---
key: been
speaker: Been Kim
website: https://beenkim.github.io/
affiliation: Google
title: Interpretability - now what?
time: TBD
picture: been.jpg
picture-note: Been Kim
slides: 
bio: |
     Been Kim is a senior research scientist at Google Brain. Her research focuses on building interpretable machine learning - making ML understandable by humans for more responsible AI. The vision of her research is to make humans empowered by machine learning, not overwhelmed by it. She gave ICML tutorial on the topic in 2017, CVPR and MLSS at University of Toronto in 2018. She is a co-workshop Chair ICLR 2019, and has been an area chair at NIPS, ICML, AISTATS and FAT* conferences. In 2018, she gave a talk at G20 meeting on digital economy summit in Argentina. In 2019, her work called TCAV received UNESCO Netexplo award for "breakthrough digital innovations with the potential of profound and lasting impact on the digital society”. This work was also a part of CEO’s keynote at Google I/O 19'. She received her PhD. from MIT. 

abstract: |
    In this talk, I hope to reflect on some of the progress made in the field of interpretable machine learning. We will reflect on where we are going as a field, and what are the things we need to be aware and be careful as we make progress. With that perspective, I will then discuss some of my recent work 1) sanity checking popular methods and 2) developing more lay person-friendly interpretability method. 


---
